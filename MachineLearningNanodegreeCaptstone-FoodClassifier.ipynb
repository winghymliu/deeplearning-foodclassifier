{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Capstone Project - Food Classifier\n",
    "\n",
    "## Overview\n",
    "\n",
    "The aim of this Capstone Project is to use deep learning to classify images of food. The notebook will include all implementation stages of the project including, data processing, training and building the model and finally an analysis of the results. \n",
    "\n",
    "## Software Requirements\n",
    "\n",
    "The project requires an installation of Anaconda with Python 2. The main libraries use will be Keras with a Tensorflow backend, panda and numpy. \n",
    "\n",
    "## Data Processing\n",
    "\n",
    "The project uses the UECFOOD256 from an academic insitute in Japan, the dataset contains 31,651 images in 256 folders with each folder being a particular category of the food."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_files    \n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "\n",
    "raw_dataset = r'UECFOOD256'\n",
    "categories = r'labels.txt' \n",
    "images_folder = r'food-images'\n",
    "train_folder = os.path.join(images_folder, 'train')\n",
    "valid_folder = os.path.join(images_folder, 'valid')\n",
    "test_folder = os.path.join(images_folder, 'test')\n",
    "\n",
    "def create_folder(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "        \n",
    "create_folder(images_folder)\n",
    "create_folder(train_folder)\n",
    "create_folder(valid_folder)\n",
    "create_folder(test_folder)\n",
    "\n",
    "labels = pd.read_csv(categories, sep=\",\", header=0)\n",
    "num_food_labels = len(labels)\n",
    "\n",
    "def get_label_from_raw(raw_label, labels):\n",
    "    return labels.iloc[int(raw_label)-1][\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cross validation\n",
    "\n",
    "Currently the images are all grouped together within their labeled folders and they need to be seperated into the training, validation and testing sets for each label. First the names of the files are loaded into a collection, then train_test_split is used to obtain the training and testing set. The method is called again to further split the training data into training and validation sets.\n",
    "\n",
    "A three folders are created: train, valid, test which each contain a subfolder with the correct label and the images from our cross validation split earlier. The methods are defined here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Function to confirm the number of files per label\n",
    "def get_total_images_per_label(path):\n",
    "    total = 0\n",
    "    for item in listdir(path):\n",
    "        image_folder = os.path.join(path, item)\n",
    "        if os.path.isdir(image_folder):        \n",
    "            images = [file for file in os.listdir(image_folder) if file.endswith('.jpg')]\n",
    "            print('Folder ' + item + ' has ' + str(len(images)) + ' images')\n",
    "            total = total + len(images)\n",
    "    print('total files ' + str(total))\n",
    "\n",
    "def train_validate_test_split(path, raw_label, labels):\n",
    "    label = get_label_from_raw(raw_label, labels)\n",
    "    image_folder = os.path.join(path, raw_label)\n",
    "    files = [file for file in os.listdir(image_folder) if file.endswith('.jpg')]  \n",
    "\n",
    "    X = np.vstack(files)\n",
    "    y = np.vstack([label] * len(files))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "        \n",
    "    return X_train, X_val, X_test, y_train,  y_val, y_test\n",
    "\n",
    "def copy_images_to_folder(src_folder, set_folder, food_label, images):\n",
    "    target_folder = os.path.join(set_folder, food_label)\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.mkdir(target_folder)\n",
    "    for image in images:        \n",
    "        src = os.path.join(src_folder, image[0])\n",
    "        dst = os.path.join(target_folder, image[0])\n",
    "        copyfile(src, dst)        \n",
    "        \n",
    "def split_and_transfer_raw_images(raw_dataset, labels):    \n",
    "    raw_labels = [int(folder) for folder in listdir(raw_dataset) if os.path.isdir(os.path.join(raw_dataset, folder))]\n",
    "    sorted_labels = sorted(raw_labels)\n",
    "    for raw_label in raw_labels:\n",
    "        if raw_label < 2:\n",
    "            raw_label = str(raw_label)\n",
    "            X_train, X_val, X_test, y_train,  y_val, y_test = train_validate_test_split(raw_dataset, raw_label, labels) \n",
    "            food_label = raw_label + '.' + get_label_from_raw(raw_label, labels)\n",
    "            src_folder = os.path.join(raw_dataset, raw_label)\n",
    "            copy_images_to_folder(src_folder, train_folder, food_label, X_train)\n",
    "            copy_images_to_folder(src_folder, valid_folder, food_label, X_val)\n",
    "            copy_images_to_folder(src_folder, test_folder, food_label, X_test)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The cross validation split is performed here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "split_and_transfer_raw_images(raw_dataset, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The data is now loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 256 total food categories.\n",
      "There are 12 total food images.\n",
      "\n",
      "There are 4 training food images.\n",
      "There are 4 validation food images.\n",
      "There are 4 test food images.\n"
     ]
    }
   ],
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np_utils.to_categorical(np.array(data['target']), len(labels))\n",
    "    return files, targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset(train_folder)\n",
    "valid_files, valid_targets = load_dataset(valid_folder)\n",
    "test_files, test_targets = load_dataset(test_folder)\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total food categories.' % num_food_labels)\n",
    "print('There are %s total food images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training food images.' % len(train_files))\n",
    "print('There are %d validation food images.' % len(valid_files))\n",
    "print('There are %d test food images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Image Resize\n",
    "\n",
    "As we construct tensors from the images, they need to be resized order to standardize the input dimensions for the convolutional neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths) if img_path.endswith('jpg')]\n",
    "    print([img_path for img_path in tqdm(img_paths) if img_path.endswith('jpg')])\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Loading the images and rescaling them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 13.46it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 23530.46it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 69.30it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 45964.98it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 52.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 42473.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food-images/train/1.rice/2.jpg', 'food-images/train/1.rice/3.jpg', 'food-images/train/1.rice/1.jpg']\n",
      "['food-images/valid/1.rice/25.jpg', 'food-images/valid/1.rice/33.jpg', 'food-images/valid/1.rice/17.jpg']\n",
      "['food-images/test/1.rice/5.jpg', 'food-images/test/1.rice/8.jpg', 'food-images/test/1.rice/18.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After creating the tensors we can view how they've been resized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "def display_samples(tensors):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(tensors[i], cmap=pyplot.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    pyplot.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "display_samples(train_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After rescaling the images, we want to perform image augmentation, this involves a few processes:\n",
    "* Standardization\n",
    "* Whitening (ZCA)\n",
    "* Random Rotations\n",
    "* Random Shifts\n",
    "* Random Flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def display_first_batch(X, y, batchsize=9):\n",
    "    for X_batch, y_batch in datagen.flow(X, y, batch_size=batchsize):\n",
    "        display_samples(X_batch)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Normalization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 1 µs, total: 12 µs\n",
      "Wall time: 13.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "datagen.fit(train_tensors)\n",
    "display_first_batch(train_tensors, train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### ZCA Whitening example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# warning doesn't run on laptop\n",
    "from keras import backend as K\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "K.set_image_dim_ordering('th')\n",
    "datagen.fit(train_tensors)\n",
    "display_first_batch(train_tensors, train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Random Rotation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "datagen = ImageDataGenerator(rotation_range=90)\n",
    "datagen.fit(train_tensors)\n",
    "display_first_batch(train_tensors, train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Random Shifts Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "shift = 0.2\n",
    "datagen = ImageDataGenerator(width_shift_range=shift, height_shift_range=shift)\n",
    "datagen.fit(train_tensors)\n",
    "display_first_batch(train_tensors, train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Random Flips Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "shift = 0.2\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "datagen.fit(train_tensors)\n",
    "display_first_batch(train_tensors, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (2,2), strides=(1,1), padding='same', input_shape=(224,224,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, (2,2), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (2,2), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_food_labels, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "epochs = 5\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "food_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "print(test_tensors[0])\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(food_predictions)==np.argmax(test_targets, axis=1))/len(food_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Image augmentation, whitening, create base model, create advanced models, record results, use transfer learning\n",
    "# Graphs visuals for results, diagram of architeture, sample images, show whitening process\n",
    "# Do write up in pdf 9 -15 pages\n",
    "# Write a readme\n",
    "# contents page for ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "food-classifier",
   "language": "python",
   "name": "food-classifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
